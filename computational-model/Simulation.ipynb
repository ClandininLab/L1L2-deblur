{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import scipy.ndimage\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.io\n",
    "import scipy.io as spio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import scipy.interpolate\n",
    "import torch.optim as optim\n",
    "from scipy.integrate import odeint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#codes adapted from https://github.com/hunse/vanhateren/tree/master/vanhateren\n",
    "\n",
    "class VanHateren:\n",
    "\n",
    "    imshape = (1024, 1536)\n",
    "\n",
    "    def __init__(self, calibrated=True):\n",
    "        self.calibrated = calibrated\n",
    "        vanhateren_dir = os.path.expanduser(\"vanhateren_imc/\")\n",
    "        self.image_dir = vanhateren_dir\n",
    "\n",
    "    @property\n",
    "    def image_ext(self):\n",
    "        return 'imc' if self.calibrated else 'iml'\n",
    "\n",
    "    def image_list(self, server=False):\n",
    "        if server:\n",
    "            return list(range(1, 4213))\n",
    "        if not os.path.exists(self.image_dir):\n",
    "            return []\n",
    "\n",
    "        pattern = 'imk([0-9]{5}).' + self.image_ext\n",
    "        numbers = []\n",
    "        for filename in os.listdir(self.image_dir):\n",
    "            match = re.match(pattern, filename)\n",
    "            if match is not None:\n",
    "                numbers.append(int(match.group(1)))\n",
    "\n",
    "        return sorted(numbers)\n",
    "\n",
    "    def image_name(self, i):\n",
    "        pattern = 'imk%05d.' + self.image_ext\n",
    "        return pattern % i\n",
    "\n",
    "    def image_path(self, i):\n",
    "        return os.path.join(self.image_dir, self.image_name(i))\n",
    "\n",
    "    def image(self, i, normalize=True):\n",
    "        path = self.image_path(i)\n",
    "        #if not os.path.exists(path):\n",
    "            \n",
    "\n",
    "        with open(path, 'rb') as handle:\n",
    "           s = handle.read()\n",
    "\n",
    "        img = np.fromstring(s, dtype='uint16').byteswap()\n",
    "\n",
    "        if normalize:\n",
    "            img = img.astype(float)\n",
    "            img -= img.min()\n",
    "            img /= img.max()\n",
    "\n",
    "        return img.reshape(self.imshape)\n",
    "\n",
    "    def images(self, inds, **kwargs):\n",
    "        images = np.zeros((len(inds),) + self.imshape)\n",
    "        for i, ind in enumerate(inds):\n",
    "            images[i] = self.image(ind, **kwargs)\n",
    "        return images\n",
    "\n",
    "    def patches(self, n, shape, n_images=10, replace=True, rng=np.random):\n",
    "        local_inds = self.image_list()\n",
    "        if len(local_inds) == 0:\n",
    "            self.download_images(range(1, n_images+1))\n",
    "            local_inds = self.image_list()\n",
    "\n",
    "        inds = rng.choice(local_inds, size=n_images, replace=replace)\n",
    "        images = self.images(inds)\n",
    "\n",
    "        im_shape = images.shape[1:]\n",
    "        kk = rng.randint(0, n_images, size=n)\n",
    "        ii = rng.randint(0, im_shape[0] - shape[0], size=n)\n",
    "        jj = rng.randint(0, im_shape[1] - shape[1], size=n)\n",
    "\n",
    "        patches = np.zeros((n,) + shape)\n",
    "        for p, [k, i, j] in enumerate(zip(kk, ii, jj)):\n",
    "            patches[p] = images[k, i:i+shape[0], j:j+shape[1]]\n",
    "\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fspecial_gauss(size, sigma):\n",
    "    x, y = np.mgrid[-size//2 + 1:size//2 + 1, -size//2 + 1:size//2 + 1]\n",
    "    g = np.exp(-((x**2 + y**2)/(2.0*sigma**2)))\n",
    "    return g/g.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "def f1(v,g):\n",
    "    if v>0:\n",
    "        return 1-g\n",
    "    else:\n",
    "        return g\n",
    "def f2(v,w1,w2):\n",
    "    if v>0:\n",
    "        return w1\n",
    "    else:\n",
    "        return w2\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self,dt,feedback=True):\n",
    "        super(Model, self).__init__()\n",
    "        self.tv = nn.Parameter(torch.tensor(0.0131))\n",
    "        self.ty = nn.Parameter(torch.tensor(0.5613))\n",
    "        self.w = nn.Parameter(torch.tensor(12.7118))\n",
    "        self.g1 = nn.Parameter(torch.tensor(0.1686))\n",
    "        self.input_scalar1 = nn.Parameter(torch.tensor(5.6441))\n",
    "        self.input_scalar2 = nn.Parameter(torch.tensor(3.4075))\n",
    "        self.dt = dt\n",
    "        self.y0 = torch.tensor(0.0)\n",
    "        self.outputbias = nn.Parameter(torch.tensor(1.1597))\n",
    "        self.outputweights = nn.Parameter(torch.tensor(0.4818))\n",
    "        self.feedback=feedback\n",
    "\n",
    "    def forward(self, sti_y, target):\n",
    "        res_list=[]\n",
    "        res_list.append(-target[0])\n",
    "        v= -target[0]\n",
    "        y= self.y0 if self.feedback else 0\n",
    "        for i in range(1,len(sti_y)):\n",
    "            if self.feedback:\n",
    "                sti=sti_y[i]*f2(sti_y[i],self.input_scalar1,self.input_scalar2)\n",
    "                dy=(-y+v*f1(v,torch.clamp(self.g1,0,1)))/self.ty*self.dt\n",
    "                dv=(-v-self.w*y-sti)/self.tv*self.dt\n",
    "                v=v+dv\n",
    "                y=y+dy\n",
    "            else:\n",
    "                sti=sti_y[i]*f2(sti_y[i],self.input_scalar1,self.input_scalar2)\n",
    "                dy=(-y+v*f1(v,torch.clamp(self.g1,0,1)))/self.ty*self.dt\n",
    "                dv=(-v-self.w*y-sti)/self.tv*self.dt\n",
    "                v=v+dv\n",
    "                y=0\n",
    "            res_list.append(self.outputweights*(v+self.outputbias))\n",
    "        res_list=torch.stack(res_list)\n",
    "        return -res_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_blurring_induced_errors_and_deblurring_multi_error(contrast, luminance, speed, cropAtMax, model, simIndVec, skipLength=2):\n",
    "    t_delay=21    \n",
    "    imageFullSize = 1024    \n",
    "    useImage = np.fliplr(contrast[0:1024, 0:1024])\n",
    "    useImage = useImage[200:800, :]\n",
    "    photoreceptorTimeConstant = 0.01\n",
    "    pixelPerDegree = 1024/60\n",
    "    speedStd = 90\n",
    "    kernelWidth = photoreceptorTimeConstant * speed * pixelPerDegree\n",
    "    expWindow = np.exp(-1/kernelWidth * np.arange(1, kernelWidth*4 + 1))\n",
    "    expWindow = expWindow[::-1]\n",
    "    expWindow /= np.sum(expWindow)\n",
    "    twoDimensionalExpWindow = np.tile(expWindow, (useImage.shape[0], 1))\n",
    "    simIndVec = simIndVec[0::skipLength]\n",
    "    blurredImage = np.zeros(useImage.shape)\n",
    "    for ii in range(len(expWindow), useImage.shape[1]):\n",
    "        blurredImage[:, ii] = np.sum(useImage[:, ii-len(expWindow):ii] * twoDimensionalExpWindow, axis=1)    \n",
    "    blurredImage[:, 0] = useImage[:, 0]\n",
    "    for ii in range(len(expWindow)):\n",
    "        useFilt = twoDimensionalExpWindow[:, 0:ii+1].copy()\n",
    "        n = np.sum(useFilt[0, :])\n",
    "        useFilt /= n\n",
    "        blurredImage[:, ii] = np.sum(useImage[:, 0:ii+1] * useFilt, axis=1)\n",
    "\n",
    "    tVec = np.linspace(0, 0.8, 1024)\n",
    "    tspan = [0, np.max(tVec)]\n",
    "    \n",
    "    deblurredValues = np.zeros((len(simIndVec), useImage.shape[1]))\n",
    "\n",
    "    for ii, useInd in enumerate(simIndVec):\n",
    "        if t_delay==0:\n",
    "            deblurredValues[ii, :] = model(torch.from_numpy(blurredImage[useInd]),[torch.Tensor([0.0])]).detach().numpy()[:,0]\n",
    "        else:\n",
    "            deblurredValues[ii, t_delay:] = model(torch.from_numpy(blurredImage[useInd]),[torch.Tensor([0.0])]).detach().numpy()[:-t_delay,0]\n",
    "    \n",
    "    shiftVal = model.outputweights.item()*model.outputbias.item()\n",
    "    diffFromBlurred = np.sign(useImage[simIndVec, :]) - np.sign(blurredImage[simIndVec, :])\n",
    "    diffFromDeblurred = np.sign(useImage[simIndVec, :]) - np.sign(deblurredValues + shiftVal)\n",
    "    diffFromDeblurred[:, 0:200] = 0\n",
    "    cropInd = np.ones(len(simIndVec)) * blurredImage.shape[1]\n",
    "\n",
    "    if cropAtMax == 1:\n",
    "        m, ix = np.max(blurredImage[simIndVec, :], axis=1)\n",
    "        for ii in range(len(ix)):\n",
    "            diffFromBlurred[ii, ix[ii]:] = 0\n",
    "            diffFromDeblurred[ii, ix[ii]:] = 0\n",
    "        cropInd = ix\n",
    "\n",
    "    errorFromBlurred = [np.sum(np.abs(diffFromBlurred)), np.sum(np.abs(diffFromBlurred * blurredImage[simIndVec, :])), np.sum(np.abs(diffFromBlurred * useImage[simIndVec, :]))]\n",
    "    errorFromDeblurred = [np.sum(np.abs(diffFromDeblurred)), np.sum(np.abs(diffFromDeblurred * blurredImage[simIndVec, :])), np.sum(np.abs(diffFromDeblurred * useImage[simIndVec, :]))]\n",
    "\n",
    "    return errorFromBlurred, errorFromDeblurred, diffFromBlurred, diffFromDeblurred, useImage, cropInd, deblurredValues, blurredImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_sampling = 0.1\n",
    "opticsBlurAngle = 5.7\n",
    "opticsBlurStd = opticsBlurAngle/(da_sampling*2*np.sqrt(2*np.log(2)))\n",
    "filterWidth = 3*opticsBlurStd*2\n",
    "g=fspecial_gauss(int(filterWidth)+1,opticsBlurStd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tVec = np.linspace(0, 0.8, 1024)\n",
    "dt=tVec[1]\n",
    "model=Model(dt)\n",
    "model.load_state_dict(\"PATH_TO_TRAINED_MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VH=VanHateren()\n",
    "img=VH.image(i,normalize=True)\n",
    "luminance=scipy.ndimage.correlate(img, g, mode='constant').transpose()\n",
    "contrast=(luminance-luminance.mean())/luminance.mean()\n",
    "errorFromBlurred, errorFromDeblurred, diffFromBlurred, diffFromDeblurred, useImage, cropInd, deblurredValues, blurredImage=calculate_blurring_induced_errors_and_deblurring_multi_error(contrast, luminance, 300, 0, model, np.arange(201))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
